{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Sorting.ipynb","provenance":[],"authorship_tag":"ABX9TyNcATEi790ysWj2PPAybJip"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"IoLWZ_0MP1tZ"},"source":["# Sorting\n","\n","Sorting is one of the more common operations, particularly when it comes to any kind of data display. For example, any program or website that allows you to search will present the results sorted by relevance or alphabetically or by date or by price or by some other metric. Searches for profiles on social media will be sorted by (social) proximity to you or number of followers if needed to break ties of relevance; leaderboards for games will be sorted by MMR or kills or what have you; and all kinds of data and stats applications that increasingly underpin major companies' daily operations all involve sorting.\n","\n","So the question is, with a common task like this, how do we sort quickly?\n","\n","## Complexity\n","\n","You're already familiar with Big O notation as a way of measuring complexity:\n","\n","* O(1) constant time\n","* O(log n) logarithmic time (understood to be base 2)\n","* O(n) linear time\n","* O(n log n) linear by logarithmic\n","* O(n<sup>2</sup>) quadratic\n","* etc.\n","\n","For sorting, we presume that we always have to look at each element at least once; this means we can't do better than O(n). Also, the slowest possible way to sort would be to take every item and compare it to every other item to make sure it comes before the ones it should come before and after the ones it should come after; this means we can't do worse than O(n<sup>2</sup>). That leaves us only a small range of possible complexities.\n","\n","Also, some algorithms can have more than one complexity depending on the input. For example, suppose an algorithm first checks whether the list is already sorted, by iterating over it and comparing each item to the next; that would be linear time. If it determines that the list is already sorted, it quits. That's the best-case scenario (the lower bound); but if it's not sorted, perhaps said algorithm then goes and uses an O(n<sup>2</sup>) solution, yielding the worst-case scenario (the upper bound).\n","\n","## Inefficient sort\n","\n","**Task 1:** Implement a sort that averages O(n<sup>2</sup>). You can do selection sort, insertion sort, or bubble sort.\n","\n","You can read up on the algorithms in more detail, but in a word:\n","\n","* Selection sort: Define a sorted and unsorted portion (initially the whole list is unsorted). Repeatedly find the lowest item in the unsorted portion of the list and move it to the end of the sorted portion.\n","\n","* Insertion sort: Define a sorted and unsorted portion (initially the whole list). Repeatedly take any item in the unsorted portion of the list and place it at the correct location in the sorted portion.\n","\n","* Bubble sort: Repeatedly pass through the list, checking each pair of items. Swap them if they are in the wrong order. When a pass makes no swaps, you're done.\n","\n","I've provided a simple test block for you... feel free to elaborate on it if you need more debugging feedback. (It assumes you return the sorted list, but that doesn't mean you can't sort it in place and then just return it.)"]},{"cell_type":"code","metadata":{"id":"VPryWceGPexs"},"source":["import random\n","sorter = _____ # insert your sort function name\n","\n","for n in [1, 10, 100, 1000, 10000]:\n","  numbers = list(range(n))\n","  random.shuffle(numbers)\n","\n","  numbers = sorter(numbers)\n","  print(numbers)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CX9Pse-gdd3h"},"source":["## Efficient sort\n","\n","**Task 2:** Implement a sort that averages O(n log n). You can do merge sort or quicksort.\n","\n","You can read up on the algorithms in more detail, but in a word:\n","\n","* Merge sort: Divide the list into sublists of length 1. Merge each pair of sublists. Repeat until there is only one sublist. Merging two sublists means: loop while neither sublist is empty; on each iteration, select the lower of the two lists' heads and append it to a third list, removing that head from its original list; if either of the two lists is longer, append the rest of it to the third list.\n","\n","* Quicksort: Select a random element as a pivot. Create two sublists: elements smaller than the pivot (\"left\") and elements greater than pivot (\"right\"). Make the pivot a third list (\"middle\"). Recurse on the left and right lists. When all sublists are length 1, join them all from left to right.\n","\n"]},{"cell_type":"code","metadata":{"id":"4jrTZI38g9cf"},"source":["import random\n","sorter = _____ # insert your second sort function name\n","\n","for n in [1, 10, 100, 1000, 10000]:\n","  numbers = list(range(n))\n","  random.shuffle(numbers)\n","\n","  numbers = sorter(numbers)\n","  print(numbers)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pT20kNBtg-XO"},"source":["**Task 3:** (Whether you did quicksort or not.) Going by the above description, how do you know that quicksort's best case is O(n log n) and its worst is O(n<sup>2</sup>)? That is, what would make it take only O(n log n) and what would make it take O(n<sup>2</sup>)?\n","\n","## Stability\n","\n","A sort is called stable if items that are equal are guaranteed to remain in their original order. It is unstable if items can swap order even when equal (a swap does not have to be guaranteed, it just has to be possible).\n","\n","**Task 4:** Pick one of your algorithms above. If it's stable, explain why equal items are guaranteed to remain in the same order. If it's unstable, give an example of a case where two equal items might be swapped."]}]}